{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CdtkTIdArGo3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SaXV05GurhZF"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RjQTWpL7rn_d",
    "outputId": "be3b36c1-8c58-424d-cec7-251e209d8ede"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>306</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"@_simplycaitlin: why do my friends hate me\" b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>5551</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@_cblaze sorry i eat pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8107</th>\n",
       "      <td>8332</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Black guy in class: *attempts to throw a paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>4569</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Princesslexii16 Fucking coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21419</th>\n",
       "      <td>21881</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>That other shit for the birds . Get over yo self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "301           306      3            1                   2        0      1   \n",
       "5394         5551      3            0                   3        0      1   \n",
       "8107         8332      6            2                   1        3      2   \n",
       "4438         4569      3            2                   1        0      0   \n",
       "21419       21881      3            0                   3        0      1   \n",
       "\n",
       "                                                   tweet  \n",
       "301    \"@_simplycaitlin: why do my friends hate me\" b...  \n",
       "5394                          @_cblaze sorry i eat pussy  \n",
       "8107   Black guy in class: *attempts to throw a paper...  \n",
       "4438                       @Princesslexii16 Fucking coon  \n",
       "21419   That other shit for the birds . Get over yo self  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PlaRObvorpbr"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "Z65U8-1grzKH",
    "outputId": "b202a825-360f-46ef-bef7-9e3581a483fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14784</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @CourtneyyKay: Cruising down the street in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama won tho. So roll tide bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "14784      3            0                   3        0      1   \n",
       "7549       3            0                   3        0      1   \n",
       "\n",
       "                                                   tweet  \n",
       "14784  RT @CourtneyyKay: Cruising down the street in ...  \n",
       "7549                 Alabama won tho. So roll tide bitch  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwE8Dvzcr031",
    "outputId": "4ff2559f-8ae6-4fd8-98cf-d60d30f2c63c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNO98BV9sCev",
    "outputId": "58c6313a-b9d3-41ac-cb92-82a0c423447b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(hate_speech\n",
       " 0    19790\n",
       " 1     3419\n",
       " 2     1251\n",
       " 3      287\n",
       " 4       21\n",
       " 5        7\n",
       " 6        5\n",
       " 7        3\n",
       " Name: count, dtype: int64,\n",
       " offensive_language\n",
       " 3    13383\n",
       " 2     4246\n",
       " 0     3475\n",
       " 1     2066\n",
       " 6      857\n",
       " 5      369\n",
       " 4      251\n",
       " 9       66\n",
       " 8       37\n",
       " 7       33\n",
       " Name: count, dtype: int64,\n",
       " neither\n",
       " 0    18892\n",
       " 3     2790\n",
       " 1     1694\n",
       " 2     1200\n",
       " 6      103\n",
       " 5       54\n",
       " 4       35\n",
       " 9        5\n",
       " 8        5\n",
       " 7        5\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech'].value_counts(), df['offensive_language'].value_counts(), df['neither'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "eIBSBF9uhcfO",
    "outputId": "3209e876-0dbb-4aa9-f8c1-c632362af383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rXMhbqxMhwR4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\",\n",
       "       '!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!',\n",
       "       '!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit',\n",
       "       ...,\n",
       "       'young buck wanna eat!!.. dat nigguh like I aint fuckin dis up again',\n",
       "       'youu got wild bitches tellin you lies',\n",
       "       '~~Ruffled | Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow &amp; white. A Coll http://t.co/H0dYEBvnZB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWCW2JZRmq--"
   },
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GhaHiGFom9Y",
    "outputId": "695c6338-a8ca-4db5-8e63-d3ed6a975b4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary data for tokenization\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LklmfFsWonEf",
    "outputId": "b94ae560-3e8b-4e8c-bcd9-47d4560c49fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # for better lemmatization support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "H-ozWCDHo5Te"
   },
   "outputs": [],
   "source": [
    "# # initialize tokenizer and stop words\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rjFbW30EmxjU"
   },
   "outputs": [],
   "source": [
    "# def text_preprocess(text):\n",
    "#     # To lower case\n",
    "#     text = text.lower()\n",
    "\n",
    "#     # remove punctuations\n",
    "    \n",
    "#     # removing rt short for retweet\n",
    "#     text = re.sub(r'\\brt\\b', '', text)\n",
    "#     # Remove usernames (words starting with @)\n",
    "#     text = re.sub(r'@\\w+', '', text)\n",
    "#     # Remove 'amp' and other isolated HTML artifacts\n",
    "#     text = re.sub(r'\\bamp\\b', '', text)\n",
    "#     # Remove punctuation and special characters\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "#     # tokenize text into words\n",
    "#     words = word_tokenize(text)\n",
    "\n",
    "#     # remove stop words\n",
    "#     filtered_tokens = [word for word in words if word not in stop_words]\n",
    "\n",
    "#     lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "#     return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child play run quickly dog run hour man fisherman fish yesterday\n"
     ]
    }
   ],
   "source": [
    "def text_preprocess(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove 'rt' (retweet), usernames, 'amp', and punctuation\n",
    "    text = re.sub(r'\\brt\\b', '', text)  # Remove 'rt' for retweet\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove usernames (words starting with @)\n",
    "    text = re.sub(r'\\bamp\\b', '', text)  # Remove 'amp' and other HTML artifacts\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Lemmatize and remove stop words using spaCy\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if token.text not in stop_words]\n",
    "\n",
    "    # Join the lemmatized tokens into a single string\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Example usage\n",
    "text = \"The children are playing and they are running quickly, but the dog has been running for hours, and the men are fishermen who were fishing yesterday.\"\n",
    "processed_text = text_preprocess(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlKz0Oe3pOaY",
    "outputId": "5ac0da03-b957-4aad-e6d7-978d23d1ffce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child play run quickly dog run hour man fisherman fish yesterday\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"The children are playing and they are running quickly, but the dog has been running for hours, and the men are fishermen who were fishing yesterday.\"\n",
    "processed_text = text_preprocess(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mK7ztSQFq7NH"
   },
   "outputs": [],
   "source": [
    "df['cleaned_tweets'] = df['tweet'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "8yevsULArvzN",
    "outputId": "74f0b8b4-e978-4095-e516-d2bed4d1f328"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman not complain clean house   man alway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>boy dat coldtyga dwn bad cuffin dat hoe 1s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>dawg    ever fuck bitch start cry confuse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear might true might faker bitch tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "      <td>shit blow meclaim faithful somebody still fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "      <td>sit hate another bitch   get much shit go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "      <td>8220 cause tired big bitch come we skinny girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "      <td>might get ya bitch back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "      <td>hobby include fight mariam \\n\\n bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "5      3            1                   2        0      1   \n",
       "6      3            0                   3        0      1   \n",
       "7      3            0                   3        0      1   \n",
       "8      3            0                   3        0      1   \n",
       "9      3            1                   2        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
       "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
       "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...   \n",
       "8  \" &amp; you might not get ya bitch back &amp; ...   \n",
       "9  \" @rhythmixx_ :hobbies include: fighting Maria...   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0      woman not complain clean house   man alway...  \n",
       "1      boy dat coldtyga dwn bad cuffin dat hoe 1s...  \n",
       "2      dawg    ever fuck bitch start cry confuse ...  \n",
       "3                                   look like tranny  \n",
       "4      shit hear might true might faker bitch tel...  \n",
       "5    shit blow meclaim faithful somebody still fu...  \n",
       "6          sit hate another bitch   get much shit go  \n",
       "7  8220 cause tired big bitch come we skinny girl...  \n",
       "8                          might get ya bitch back    \n",
       "9              hobby include fight mariam \\n\\n bitch  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    woman not complain clean house   man always take trash'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "J8eBUE07rzxa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    boy dat coldtyga dwn bad cuffin dat hoe 1st place'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1 = df[df['class'] == 1].sample(10000, random_state=42)\n",
    "class_0 = df[df['class'] == 0]\n",
    "class_2 = df[df['class'] == 2]\n",
    "\n",
    "class_1.shape, class_0.shape, class_2.shape\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "zero_upsampled = resample(class_0, replace=True, n_samples=7000, random_state=42)\n",
    "two_upsampled = resample(class_2, replace=True, n_samples=7000, random_state=42)\n",
    "\n",
    "# Combine the oversampled data with the '1' class\n",
    "balanced_df = pd.concat([class_1, zero_upsampled, two_upsampled])\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_df.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>That, and we spent half of our junior year and...</td>\n",
       "      <td>spend half junior year senior year bitching du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @JohnBishop100: Top tip of the day - if you...</td>\n",
       "      <td>top tip day   want inconspicuous elbow gig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>@slayerific13 @brenda_skelton @daisymcgarr I d...</td>\n",
       "      <td>not hunt bird unless count shooting dive s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   3        0      1   \n",
       "1      3            0                   0        3      2   \n",
       "2      3            0                   0        3      2   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  That, and we spent half of our junior year and...   \n",
       "1  RT @JohnBishop100: Top tip of the day - if you...   \n",
       "2  @slayerific13 @brenda_skelton @daisymcgarr I d...   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0  spend half junior year senior year bitching du...  \n",
       "1     top tip day   want inconspicuous elbow gig ...  \n",
       "2      not hunt bird unless count shooting dive s...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    10000\n",
       "2     7000\n",
       "0     7000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAuYVq9QxKR5"
   },
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "jNJVpcyqxNh4"
   },
   "outputs": [],
   "source": [
    "# x = df.drop(columns=['class'])\n",
    "\n",
    "x = balanced_df[['cleaned_tweets', 'hate_speech', 'offensive_language', 'neither']] \n",
    "y = balanced_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "sg_uXu60xNyd"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfuAfDFDxN_B",
    "outputId": "9abc0cfc-8e0c-456b-ad1d-d280de1638de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19200, 4), (4800, 4), (19200,), (4800,))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaJ8gW4zxiKf"
   },
   "source": [
    "## Applying TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "z8xFdo-OxopG"
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "nWyDNyoixozt"
   },
   "outputs": [],
   "source": [
    "tf_train_data = tf_idf.fit_transform(x_train['cleaned_tweets'])\n",
    "tf_test_data = tf_idf.transform(x_test['cleaned_tweets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gV2tX5Mmxo99",
    "outputId": "507028bb-31b9-46b1-c1a3-4e04df0b2285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19200, 16539), (4800, 16539))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_data.shape, tf_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_train_data.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Wf5aQILvF00"
   },
   "source": [
    "## Balancing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G824K1U8yTZk"
   },
   "source": [
    "Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "W4W-qbuavHew"
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "oQ8Sw4uDy3AS"
   },
   "outputs": [],
   "source": [
    "x_train_balanced, y_train_balanced = smote.fit_resample(tf_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c8lAMInzFIH",
    "outputId": "15fa486f-5799-4292-f9e3-3ee1b416d2a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23979, 16539), (23979,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_balanced.shape, y_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "OqviCc1zzHJ9",
    "outputId": "cc5887c6-1ede-4fe9-9ef6-5249ad0612d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    7993\n",
       "1    7993\n",
       "2    7993\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94A5igqwzL5r"
   },
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "NLoHBUB_zN6f"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac8x1qYa0vG2",
    "outputId": "4b38c0ce-b4a1-4370-90fb-45ff137672ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9508333333333333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1401\n",
      "           1       0.97      0.91      0.94      2007\n",
      "           2       0.94      0.97      0.96      1392\n",
      "\n",
      "    accuracy                           0.95      4800\n",
      "   macro avg       0.95      0.96      0.95      4800\n",
      "weighted avg       0.95      0.95      0.95      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "ranfor_model = RandomForestClassifier(n_estimators=70, random_state=42)\n",
    "ranfor_model.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred2 = ranfor_model.predict(tf_test_data)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 1) I hate this place, it's full of rude people! #frustrated (Offensive)\n",
      "Predicted Class: Hate\n",
      "-------------------------------\n",
      "Tweet: 2) This is an amazing movie! I loved every second of it! 😍 (Neither)\n",
      "Predicted Class: Neither\n",
      "-------------------------------\n",
      "Tweet: 3) Why is everyone so mean on the internet these days? 😡 (Offensive)\n",
      "Predicted Class: Offensive Language\n",
      "-------------------------------\n",
      "Tweet: 4) I love learning new things, it's such a great experience. (Neither)\n",
      "Predicted Class: Neither\n",
      "-------------------------------\n",
      "Tweet: 5) I am so sick of the traffic today, it's ridiculous! 🚗 (Offensive)\n",
      "Predicted Class: Neither\n",
      "-------------------------------\n",
      "Tweet: 6) You are such a worthless piece of garbage! 🤬 (Hate)\n",
      "Predicted Class: Hate\n",
      "-------------------------------\n",
      "Tweet: 7) I don't understand why people are still so stupid about climate change! 🌍 (Offensive)\n",
      "Predicted Class: Offensive Language\n",
      "-------------------------------\n",
      "Tweet: 8) I absolutely love my new puppy, she's the cutest thing ever! 🐶 (Neither)\n",
      "Predicted Class: Neither\n",
      "-------------------------------\n",
      "Tweet: 9) People who are racist are disgusting, they should be ashamed of themselves. 😡 (Hate)\n",
      "Predicted Class: Hate\n",
      "-------------------------------\n",
      "Tweet: 10) This restaurant has the worst food I've ever tasted, what a waste of money! 😤 (Offensive)\n",
      "Predicted Class: Offensive Language\n",
      "-------------------------------\n",
      "Tweet: 11) I'm so proud of what we've accomplished, it's an amazing feeling! 🏆 (Neither)\n",
      "Predicted Class: Neither\n",
      "-------------------------------\n",
      "Tweet: 12) Why are all men so pathetic? It's honestly so embarrassing. 😒 (Hate)\n",
      "Predicted Class: Hate\n",
      "-------------------------------\n",
      "Tweet: 13) i hate jung ki soo much \n",
      "Predicted Class: Offensive Language\n",
      "-------------------------------\n",
      "Tweet: 14) you are such a disgusting person\n",
      "Predicted Class: Neither\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example new tweets for testing\n",
    "new_tweets = [\n",
    "    \"1) I hate this place, it's full of rude people! #frustrated (Offensive)\",  # Offensive Language\n",
    "    \"2) This is an amazing movie! I loved every second of it! 😍 (Neither)\",  # Neither (Positive, neutral)\n",
    "    \"3) Why is everyone so mean on the internet these days? 😡 (Offensive)\",  # Offensive Language (Expressing frustration towards people being mean)\n",
    "    \"4) I love learning new things, it's such a great experience. (Neither)\",  # Neither (Positive, neutral)\n",
    "    \"5) I am so sick of the traffic today, it's ridiculous! 🚗 (Offensive)\",  # Offensive Language (Expressing frustration with traffic, negative tone but not targeting specific people or using hate speech)\n",
    "    \"6) You are such a worthless piece of garbage! 🤬 (Hate)\",  # Hate speech\n",
    "    \"7) I don't understand why people are still so stupid about climate change! 🌍 (Offensive)\",  # Offensive language\n",
    "    \"8) I absolutely love my new puppy, she's the cutest thing ever! 🐶 (Neither)\",  # Neither (neutral)\n",
    "    \"9) People who are racist are disgusting, they should be ashamed of themselves. 😡 (Hate)\",  # Hate speech\n",
    "    \"10) This restaurant has the worst food I've ever tasted, what a waste of money! 😤 (Offensive)\",  # Offensive language\n",
    "    \"11) I'm so proud of what we've accomplished, it's an amazing feeling! 🏆 (Neither)\",  # Neither (positive)\n",
    "    \"12) Why are all men so pathetic? It's honestly so embarrassing. 😒 (Hate)\", # Hate speech\n",
    "    \"13) i hate jung ki soo much \", # Hate speech\n",
    "    \"14) you are such a disgusting person\"\n",
    "]\n",
    "\n",
    "# Step 1: Preprocess the new tweets\n",
    "# Use the same preprocessing function that was applied during training\n",
    "new_cleaned_tweets = [text_preprocess(tweet) for tweet in new_tweets]\n",
    "\n",
    "# Step 2: Transform the tweets using the trained TF-IDF vectorizer\n",
    "new_tf_data = tf_idf.transform(new_cleaned_tweets)\n",
    "\n",
    "# Step 3: Predict the class of the new tweets using the trained RandomForest model\n",
    "new_predictions = ranfor_model.predict(new_tf_data)\n",
    "\n",
    "# Print the results\n",
    "for tweet, prediction in zip(new_tweets, new_predictions):\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    if prediction == 0:\n",
    "        print(f\"Predicted Class: Hate\")\n",
    "    elif prediction == 1:\n",
    "        print(f\"Predicted Class: Offensive Language\")\n",
    "    elif prediction == 2:\n",
    "        print(f\"Predicted Class: Neither\")\n",
    "    print(\"-------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with some other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9477272727272728\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1217\n",
      "           1       0.95      0.94      0.94      2009\n",
      "           2       0.94      0.94      0.94      1174\n",
      "\n",
      "    accuracy                           0.95      4400\n",
      "   macro avg       0.95      0.95      0.95      4400\n",
      "weighted avg       0.95      0.95      0.95      4400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "ranfor_model = RandomForestClassifier()\n",
    "ranfor_model.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred2 = ranfor_model.predict(tf_test_data)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf (12000) gives 88% Accuracy, while tf-idf(15000) gives 89% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac8x1qYa0vG2",
    "outputId": "4b38c0ce-b4a1-4370-90fb-45ff137672ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8833972160580996\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.32      0.38       290\n",
      "           1       0.93      0.93      0.93      3832\n",
      "           2       0.79      0.84      0.82       835\n",
      "\n",
      "    accuracy                           0.88      4957\n",
      "   macro avg       0.72      0.70      0.71      4957\n",
      "weighted avg       0.88      0.88      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model\n",
    "ranfor_model = RandomForestClassifier()\n",
    "ranfor_model.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred2 = ranfor_model.predict(tf_test_data)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Models...\n",
      "........................................................................................................................\n",
      "\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.8583820859390761\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.49      0.38       290\n",
      "           1       0.95      0.88      0.91      3832\n",
      "           2       0.77      0.89      0.82       835\n",
      "\n",
      "    accuracy                           0.86      4957\n",
      "   macro avg       0.68      0.75      0.71      4957\n",
      "weighted avg       0.88      0.86      0.87      4957\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8882388541456526\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.33      0.40       290\n",
      "           1       0.93      0.94      0.93      3832\n",
      "           2       0.81      0.84      0.82       835\n",
      "\n",
      "    accuracy                           0.89      4957\n",
      "   macro avg       0.74      0.70      0.72      4957\n",
      "weighted avg       0.88      0.89      0.88      4957\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tuning parameters\n",
    "\n",
    "print(\"Starting Training Models...\")\n",
    "\n",
    "print(\"...\" * 40)\n",
    "\n",
    "\n",
    "# Initialize models for comparison\n",
    "models = {\n",
    "#     \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=300, C=2.0, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=40, random_state=42, class_weight='balanced'),\n",
    "#     \"SVC\": SVC(C=1.5, kernel='linear', class_weight='balanced')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(x_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(tf_test_data)\n",
    "    print(f\"\\n\\nModel: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voh3ntvO0KFg",
    "outputId": "8c7c592a-7aad-48b2-e87f-0db82b6f4141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7859592495460964\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.56      0.31       290\n",
      "           1       0.93      0.81      0.87      3832\n",
      "           2       0.73      0.75      0.74       835\n",
      "\n",
      "    accuracy                           0.79      4957\n",
      "   macro avg       0.62      0.71      0.64      4957\n",
      "weighted avg       0.86      0.79      0.81      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = nb_model.predict(tf_test_data)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OW55btYY0l3T",
    "outputId": "d67df49e-8f04-4a7b-9027-bc5d52411b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7859592495460964\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.56      0.31       290\n",
      "           1       0.93      0.81      0.87      3832\n",
      "           2       0.73      0.75      0.74       835\n",
      "\n",
      "    accuracy                           0.79      4957\n",
      "   macro avg       0.62      0.71      0.64      4957\n",
      "weighted avg       0.86      0.79      0.81      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred1 = nb_model.predict(tf_test_data)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlDHMIHJ1JzI",
    "outputId": "ff6f8724-9b7c-41d3-f623-d9642f317f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8739156748033085\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.43      0.37       290\n",
      "           1       0.95      0.90      0.92      3832\n",
      "           2       0.82      0.89      0.85       835\n",
      "\n",
      "    accuracy                           0.87      4957\n",
      "   macro avg       0.70      0.74      0.72      4957\n",
      "weighted avg       0.89      0.87      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(x_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred3 = svm_model.predict(tf_test_data)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred3))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ki4sD--q12NP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
